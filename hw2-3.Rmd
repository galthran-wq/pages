---
title: "HW2 задача 3"
output: 
  html_document:
    code_folding: show
date: '2023-10-09'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, class.source="hide"}
sample_from_density = function(n, pdf_f, approx=1000, ...) {
  x = seq(-10, 10, length.out = approx)
  y = sapply(x, pdf_f, ...)

  random.points <- approx(
    cumsum(y)/sum(y),
    x,
    runif(n)
  )$y
  random.points
}
rlongtailed_normal = function(sd=1, mean=0, c) {
  found
}

dlongtailed_normal = function(x, c, sd=1, mean=0, normal_range=c(0, 4)) {
  if (x >= normal_range[1] & x <= normal_range[2]) {
    return(dnorm(x, mean=mean, sd=sd))
  } else { 
    if (x < 0) {
      return(c * exp(x))
    } else {
      return(c * exp(8 - 2*x))
    }
  }
}

integrate = function(fn, x_range=seq(-10, 10, length.out=100), ...) {
  lambda = abs(abs(x_range[2]) - abs(x_range[1]))
  res = 0
  for (x in x_range) {
    res = res + fn(x, ...) * (lambda)
  }
  res
}

estimate_c = function(sd, mean, tol=0.01) {
  grid = seq(-100, 100, length.out=10000)
  
  for (c in grid) {
    total_proba = integrate(fn=dlongtailed_normal, sd=sd, mean=mean, c=c)
    #
    #for (x in x_range) {
    #  total_proba = total_proba + dlongtailed_normal(x, sd=sd, mean=mean, c=c) * (1 / length(x_range))
    #}
    if (abs(total_proba - 1) < tol) {
      return(c)
    }
  }
}
```

```{r}
x_range = seq(-10, 10, length.out = 300)
mean=1
sd=2
c_est = estimate_c(sd=sd, mean=mean)
```

Напоминание: вот так выглядит распределение из задачи 3 п.5, ДЗ1:
```{r}
plot( 
  x_range, 
  lapply(x_range, dlongtailed_normal, c=c_est, mean=mean, sd=sd), 
  type='l',
  xlab = "x", ylab = "f(x)",
  sub=paste("Плотность, где c выбран так, чтобы интегрировалось к 1 (c = ", round(c_est, 2), ")")
)
```
```{r}
mean_estimator = function(sample) {
  mean(sample)
}
pearson_tukey_5q= function(sample) {
  n = length(sample)
  var_series = sort(sample)
  1/6 * (var_series[floor(n/16)+1] + var_series[floor(n/4)+1] + 2*var_series[floor(n/2)+1] + var_series[floor(3*n/4)+1] + var_series[floor(15*n/16)])
}
pearson_tukey_5q= function(sample) {
  n = length(sample)
  var_series = sort(sample)
  1/6 * (var_series[floor(n/16)+1] + var_series[floor(n/4)+1] + 2*var_series[floor(n/2)+1] + var_series[floor(3*n/4)+1] + var_series[floor(15*n/16)])
}
ogawa = function(sample, discard_n=2) {
  n = length(sample)
  var_series = sort(sample)
  mean(var_series[seq(discard_n+1,n-discard_n)])
}

#sample_from_density(5, dlongtailed_normal, mean=mean, sd=sd, c=c_est)
#c(pearson_tukey_5q(c(1,3,3,2,5)), mean(c(1,3,3,2,5)))
#ogawa(c(1,2,6,8,9), discard_n = 1)
```
```{r}
#set.seed(42)
#sample_from_density(10, dlongtailed_normal,  c=c_est, mean=mean, sd=sd)
```

```{r}
r_1 = function (estimates, true) {
  mean((true - estimates)^2)
}

r_2 = function(estimates, true) {
  risks = c()
  for (estimate in estimates) {
    risks = append(risks, min(5, (true - estimate)^3))
  }
  mean(risks)
}

r_3 = function(estimates, true) {
  risks = c()
  for (estimate in estimates) {
    dev = abs(estimate - true)
    if (dev < 0.5) {
      risks = append(risks, 0)
    } else{
      risks = append(risks, 1)
    }
  }
  mean(risks)
}
bootstrap_risk = function(n_samples, estimator, risk_f, n_iter=100) {
  estimates = c()
  for (i in seq(n_iter)) {
    sample = sample_from_density(n_samples, dlongtailed_normal,  c=c_est, mean=mean, sd=sd)
    estimate = estimator(sample)
    estimates = append(estimates, estimate)
  }
  risk_f(estimates, mean)
}
#bootstrap_risk(5, estimator=mean_estimator, risk_f=r_1)
```
```{r}
```

Посчитаем риски для всех видов оценок, для разных размеров выборок:

```{r,  class.source="hide"}
set.seed(42)
all_n_samples = c(5, 10, 20, 40)
mean_mse = c()
mean_r2 = c()
mean_r3 = c()
pt_mse = c()
pt_r2 = c()
pt_r3 = c()
ogawa_mse = c()
ogawa_r2 = c()
ogawa_r3 = c()
for (n_samples in all_n_samples) {
  print(paste("Размер выборки: ", n_samples))
  
  print("Среднее арифметическое: ")
  current_mean_mse = bootstrap_risk(n_samples, estimator= mean_estimator, risk_f=r_1)
  current_r2 = bootstrap_risk(n_samples, estimator= mean_estimator, risk_f=r_2)
  current_r3 = bootstrap_risk(n_samples, estimator= mean_estimator, risk_f=r_3)
  mean_mse = append(mean_mse, current_mean_mse)
  mean_r2 = append(mean_r2, current_r2)
  mean_r3 = append(mean_r3, current_r3)
  print(paste("(1) квадратичный риск: ", current_mean_mse))
  print(paste("(2) риск: ", current_r2))
  print(paste("(3) риск: ", current_r3))
        
  print("оценка Пирсона-Тьюки 5 квантилей: ")
  current_pt_mse = bootstrap_risk(n_samples, estimator= pearson_tukey_5q, risk_f=r_1)
  current_pt_r2 = bootstrap_risk(n_samples, estimator= pearson_tukey_5q, risk_f=r_2)
  current_pt_r3 = bootstrap_risk(n_samples, estimator= pearson_tukey_5q, risk_f=r_3)
  pt_mse = append(pt_mse, current_pt_mse)
  pt_r2 = append(pt_r2, current_pt_r2)
  pt_r3 = append(pt_r3, current_pt_r3)
  print(paste("(1) квадратичный риск: ", current_pt_mse))
  print(paste("(2) риск: ", current_pt_r2))
  print(paste("(3) риск: ", current_pt_r3))
        
  print("оценка Огавы с отбрасыванием 2 слева и справа: ")
  current_ogawa_mse = bootstrap_risk(n_samples, estimator= ogawa, risk_f=r_1)
  current_ogawa_r2 = bootstrap_risk(n_samples, estimator= ogawa, risk_f=r_2)
  current_ogawa_r3 = bootstrap_risk(n_samples, estimator= ogawa, risk_f=r_3)
  ogawa_mse = append(ogawa_mse, current_ogawa_mse)
  ogawa_r2 = append(ogawa_r2, current_ogawa_r2)
  ogawa_r3 = append(ogawa_r3, current_ogawa_r3)
  print(paste("(1) квадратичный риск: ", current_ogawa_mse))
  print(paste("(2) риск: ", current_ogawa_r2))
  print(paste("(3) риск: ", current_ogawa_r3))
}
```



```{r}
plot(all_n_samples, mean_mse, type='l', col='red', main="Квадратичный риск")
lines(all_n_samples, pt_mse, col='blue')
lines(all_n_samples, ogawa_mse, col='green')
legend(20, 0.8, legend=c("Среднее арифметическое", "Пирсон-Тьюки", "Огава"),
       col=c("red", "blue", "green"), lty=1:3, cex=0.8)
```
```{r}
plot(all_n_samples, mean_r2, type='l', col='red', main="риск 2")
lines(all_n_samples, pt_r2, col='blue')
lines(all_n_samples, ogawa_r2, col='green')
legend(20, -0.6, legend=c("Среднее арифметическое", "Пирсон-Тьюки", "Огава"),
       col=c("red", "blue", "green"), lty=1:3, cex=0.8)

```
```{r}
plot(all_n_samples, mean_r3, type='l', col='red', main="риск 3")
lines(all_n_samples, pt_r3, col='blue')
lines(all_n_samples, ogawa_r3, col='green')
legend(30, 0.5, legend=c("Среднее арифметическое", "Пирсон-Тьюки", "Огава"),
       col=c("red", "blue", "green"), lty=1:3, cex=0.8)
```
Результаты:

- Среднее арифметическое имеет наименьший квадратичный риск

Единственное исключение: при n=10 уступает оценке Пирсона-Тьюки

- Среднее арифметическое имеет наибольший (2) риск

Единственное исключение: при n=20 уступает оценке Огавы

- Среднее арифметическое имеет наименьший (3) риск
- С увеличением размера выборки разница между оценками становится менее выражена

Поведением риска с увеличением размера выборки:

- Квадратичный риск убывает с увеличением размера выборки (для всех оценок).

Единственное исключение: оценка Пирсона-Тьюки 5 кванителей при n=10 и n=20 -- можно списать на шум

- (2) риск увеличивается с ростом размера выборки для всех оценок

- (3) риск тоже уменьшается с увеличением размера выборки для всех оценок

### Вывод: 

- среднее арифметическое лучше всего оценивает $\mu=2$ (среднее неиспорченного распределения (которое было нормальным)) -- для всех рисков
- оценка Пирсона-Тьюки лучше чем оценка Огавы для маленьких выборок; оценка Огавы лучше для больших -- для всех рисков

Оценим скорость убывания

Степенной рост: $y=\beta n^{\alpha}$
Экспоненциальный рост: $y=\beta \exp{\alpha n}$

```{r}
library(knitr)
options(warn=-1)
get_decrease_speed = function (mean_mse, all_n_samples) {
  mean_mse = abs(mean_mse)
  # step_speed = mean((log(mean_mse) - lm(y~x+1, data=data.frame(y=log(mean_mse), x=log(all_n_samples)))$residuals)**2)
  # exp_speed = mean((log(mean_mse) - lm(y~x+1, data=data.frame(y=log(mean_mse), x=all_n_samples))$residuals)**2)
  step_model = NULL
  exp_model = NULL
  best_exp_speed = -99
  best_step_speed = -99
  best_exp_offset = NULL
  best_step_offset = NULL
  suppressWarnings({
  for (offset in seq(0, 0, length.out=1)) {
    step_model_i = lm(y~x+1, data=data.frame(y=log(mean_mse-offset), x=log(all_n_samples)))
    step_speed = mean(step_model_i$residuals**2)
    exp_model_i = lm(y~x+1, data=data.frame(y=log(mean_mse-offset), x=all_n_samples))
    exp_speed = mean(exp_model_i$residuals**2)
    if (step_speed > best_step_speed) {
      step_model = step_model_i
      best_step_offset = offset
      best_step_speed = step_speed
    }
    if (exp_speed > best_exp_speed) {
      exp_model = exp_model_i
      best_exp_offset = offset
      best_exp_speed = exp_speed
    }
  }
  })
  print(paste("Ошибка степенная ", round(step_speed, 3)))
  print(paste("Найденное степенной коэффициент альфа: ", round(step_model$coefficients[2], 3)))
  # print(paste("Найденный степенное смещение: ", round(best_step_offset, 3)))
  print(paste("Найденный степенной коэффициент бета: ", round(exp(step_model$coefficients[1]), 3)))
  print(paste("Ошибка экспоненциального роста ", round(exp_speed, 3)))
  print(paste("Найденный экспоненциальный коэффициент альфа: ", round(exp_model$coefficients[2], 3)))
  print(paste("Найденный эскпоненциальный коэффициент бета: ", round(exp(exp_model$coefficients[1]), 3)))
  # print(paste("Найденный эскпоненциальное смещение: ", round(best_exp_offset, 3)))
  if (step_speed < exp_speed) {
    print("Вывод: степенной рост")
  } else {
    print("Вывод: экспоненицальный рост")
  }
  list("step_model"=step_model, "exp_model"=exp_model, "step_offset"=best_step_offset, "exp_offset"=best_exp_offset)
}

mylist = list(
  "среднее арифм риск 1"=mean_mse,
  "среднее арифм риск 2"=mean_r2,
  "среднее арифм риск 3"=mean_r3,
  "Пирсон-Тьюки риск 1"=pt_mse,
  "Пирсон-Тьюки риск 2"=pt_r2,
  "Пирсон-Тьюки риск 3"=pt_r3,
  "Огава риск 1"=ogawa_mse,
  "Огава риск 2"=ogawa_r2,
  "Огава риск 3"=ogawa_r3
)
for (i in seq_along(mylist)) {
  risk = mylist[[i]]
  name = names(mylist)[i]
  print(name)
  models = get_decrease_speed(risk, all_n_samples)
}

```


```{r}
plot(all_n_samples, mean_mse, type='l', col='red', main="Квадратичный риск для среднего арифметического")
pred = exp(predict(get_decrease_speed(mean_mse, all_n_samples)$step_model, data.frame(x=log(all_n_samples))))
pred_exp = exp(predict(get_decrease_speed(mean_mse, all_n_samples)$exp_model, data.frame(x=(all_n_samples))))
lines(all_n_samples, pred, col="blue")
lines(all_n_samples, pred_exp, col="green")
legend(20, 0.8, legend=c("Настоящий риск", "Предсказанный степенной", "Предсказанный экспоненциальный"),
       col=c("red", "blue", "green"), lty=1:3, cex=0.8)
```

```{r, class.source="hide"}
plot(all_n_samples, mean_r3, type='l', col='red', main="Третий риск для среднего арифметического")
gds = get_decrease_speed(mean_r3, all_n_samples)

step_model = gds$step_model
step_offset = gds$step_offset
exp_model = gds$exp_model
exp_offset = gds$exp_offset

pred = exp(predict(step_model, data.frame(x=log(all_n_samples)))) + step_offset
pred_exp = exp(predict(exp_model, data.frame(x=(all_n_samples)))) + exp_offset
lines(all_n_samples, pred, col="blue")
lines(all_n_samples, pred_exp, col="green")
legend(20, 0.5, legend=c("Настоящий риск", "Предсказанный степенной", "Предсказанный экспоненциальный"),
       col=c("red", "blue", "green"), lty=1:3, cex=0.8)

```

```{r}
plot(all_n_samples, mean_r2, type='l', col='red', main="Второй риск для среднего арифметического")
gds = get_decrease_speed(mean_r2, all_n_samples)

step_model = gds$step_model
step_offset = gds$step_offset
exp_model = gds$exp_model
exp_offset = gds$exp_offset

pred = -exp(predict(step_model, data.frame(x=log(all_n_samples)))) + step_offset
pred_exp = -exp(predict(exp_model, data.frame(x=(all_n_samples)))) + exp_offset
lines(all_n_samples, pred, col="blue")
lines(all_n_samples, pred_exp, col="green")
legend(20, -0.4, legend=c("Настоящий риск", "Предсказанный степенной", "Предсказанный экспоненциальный"),
       col=c("red", "blue", "green"), lty=1:3, cex=0.8)

```
```{r}
plot(all_n_samples, ogawa_r3, type='l', col='red', main="Третий риск для оценки Огавы")
gds = get_decrease_speed(ogawa_r3, all_n_samples)

step_model = gds$step_model
step_offset = gds$step_offset
exp_model = gds$exp_model
exp_offset = gds$exp_offset

pred = exp(predict(step_model, data.frame(x=log(all_n_samples)))) + step_offset
pred_exp = exp(predict(exp_model, data.frame(x=(all_n_samples)))) + exp_offset
lines(all_n_samples, pred, col="blue")
lines(all_n_samples, pred_exp, col="green")
legend(20, 0.65, legend=c("Настоящий риск", "Предсказанный степенной", "Предсказанный экспоненциальный"),
       col=c("red", "blue", "green"), lty=1:3, cex=0.8)

```

```{r}
pred_exp
```

Вывод: степенной рост в каждом из случаев меньше по погрешности. Но в некоторых случаях они степенной и эскпоненциальный рост одинаково хорошо приближают данные (в частности, для риска 3). Это значит что для более точной оценки необходимо больше наблюдений. Исходя из имеющихся данных, степенной рост не хуже во всех случаях.